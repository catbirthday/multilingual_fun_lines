=== Source: dialogue5_29.txt ===
Actor: english_4
Content Type: dialogue

=== Dialogue ===

Character 1: Hey, I need help optimizing my mixing workflow. I'm spending like eight hours on a single track.

Character 2: Oh wow, eight hours is, uh, definitely excessive for a single track. So let me guess—you're probably doing everything in serial processing instead of parallel, right? Most people don't realize they should be setting up their aux sends before they even touch the channel strip.

Character 1: I don't even know what parallel processing means in this context.

Character 2: Okay so, mm, basically you want to split your signal path into multiple simultaneous chains. Like, send your dry vocal to three different aux busses—one for compression, one for reverb, one for harmonic excitation—then blend them back together instead of stacking everything inline which just, er, destroys your phase coherence.

Character 1: Phase coherence? Is that why my mixes sound muddy?

Character 2: [sneeze] Excuse me, sorry—yeah, phase coherence is huge. When you're running, let's say, your kick through an 1176 into an SSL bus comp into a Pultec, you're adding like 15 to 20 milliseconds of plugin latency plus phase rotation at every stage.

Character 1: So what should I be doing instead?

Character 2: [stuttering] W-well, first thing is you need to, to understand your gain staging hierarchy. Start with your, um, your RMS levels hitting negative 18 dBFS at the input stage, then use VCA grouping for your stems—drums, bass, guitars, vocals—before they hit your mix bus processing.

Character 1: Negative 18? I've been mixing with everything peaking at like negative 6.

Character 2: Oh man, yeah that's... that's way too hot. You're probably driving all your plugins into nonlinear distortion territory. See, most analog emulations are calibrated for negative 18 because that equals 0 VU on actual hardware, which gives you, I dunno, proper harmonic saturation instead of digital clipping.

Character 1: [sigh] This is getting really complicated. Can you just tell me a basic signal flow?

Character 2: Sure sure, so, er, here's what I do: Track at 24-bit 48k minimum, leave 12 dB of headroom, high-pass everything that isn't bass or kick at like 80 Hz, then use dynamic EQ instead of static cuts because it preserves your transient response way better.

Character 1: Dynamic EQ? That's different from regular EQ?

Character 2: Totally different beast, yeah. Regular parametric EQ is just, mm, static frequency manipulation, but dynamic EQ only engages when the threshold is exceeded at that specific frequency band. So like, you can tame harsh 3k resonances in vocals without dulling the entire presence range.

Character 1: What about compression? I never know how much to use.

Character 2: Ahh, compression is where everyone screws up because they're not thinking about, um, attack and release times in relation to tempo. Your attack should be slow enough to let transients through—we're talking 10 to 30 milliseconds—and your release should be timed to the song's pulse, usually around 60,000 divided by BPM in milliseconds.

Character 1: That's a formula? 60,000 divided by BPM?

Character 2: [bored] Yeah, it's basic math for quarter note timing. But honestly, what you really should focus on is parallel compression with, er, super aggressive settings—like 10:1 ratio, fast attack, blend it in at maybe 15 percent—because that preserves dynamics while adding density and, you know, perceived loudness without squashing everything.

Character 1: And this will cut my mixing time down from eight hours?

Character 2: Mmm, if you set up a proper template with all your routing, aux sends, and basic processing chains ready to go? You're looking at, I'd say, two hours max for a solid mix, maybe three if you're doing heavy automation on the vocal rides and, um, working with poorly recorded source material.

